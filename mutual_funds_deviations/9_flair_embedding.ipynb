{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# init embedding\n",
    "glove_embedding = WordEmbeddings('glove')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"The\"\n",
      "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
      "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
      "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
      "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
      "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
      "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
      "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
      "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
      "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
      "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
      "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
      "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
      "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
      "Token[1]: \"grass\"\n",
      "tensor([-0.8135,  0.9404, -0.2405, -0.1350,  0.0557,  0.3363,  0.0802, -0.1015,\n",
      "        -0.5478, -0.3537,  0.0734,  0.2587,  0.1987, -0.1433,  0.2507,  0.4281,\n",
      "         0.1950,  0.5346,  0.7424,  0.0578, -0.3178,  0.9436,  0.8145, -0.0824,\n",
      "         0.6166,  0.7284, -0.3262, -1.3641,  0.1232,  0.5373, -0.5123,  0.0246,\n",
      "         1.0822, -0.2296,  0.6039,  0.5541, -0.9610,  0.4803,  0.0022,  0.5591,\n",
      "        -0.1637, -0.8468,  0.0741, -0.6216,  0.0260, -0.5162, -0.0525, -0.1418,\n",
      "        -0.0161, -0.4972, -0.5534, -0.4037,  0.5096,  1.0276, -0.0840, -1.1179,\n",
      "         0.3226,  0.4928,  0.9488,  0.2040,  0.5388,  0.8397, -0.0689,  0.3136,\n",
      "         1.0450, -0.2267, -0.0896, -0.6427,  0.6443, -1.1001, -0.0096,  0.2668,\n",
      "        -0.3230, -0.6065,  0.0479, -0.1664,  0.8571,  0.2335,  0.2539,  1.2546,\n",
      "         0.5472, -0.1980, -0.7186,  0.2076, -0.2587, -0.3650,  0.0834,  0.6932,\n",
      "         0.1574,  1.0931,  0.0913, -1.3773, -0.2717,  0.7071,  0.1872, -0.3307,\n",
      "        -0.2836,  0.1030,  1.2228,  0.8374])\n",
      "Token[2]: \"is\"\n",
      "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
      "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
      "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
      "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
      "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
      "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
      "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
      "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
      "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
      "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
      "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
      "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
      "        -0.0442, -1.2969,  0.7622,  0.4635])\n",
      "Token[3]: \"green\"\n",
      "tensor([-6.7907e-01,  3.4908e-01, -2.3984e-01, -9.9652e-01,  7.3782e-01,\n",
      "        -6.5911e-04,  2.8010e-01,  1.7287e-02, -3.6063e-01,  3.6955e-02,\n",
      "        -4.0395e-01,  2.4092e-02,  2.8958e-01,  4.0497e-01,  6.9992e-01,\n",
      "         2.5269e-01,  8.0350e-01,  4.9370e-02,  1.5562e-01, -6.3286e-03,\n",
      "        -2.9414e-01,  1.4728e-01,  1.8977e-01, -5.1791e-01,  3.6986e-01,\n",
      "         7.4582e-01,  8.2689e-02, -7.2601e-01, -4.0939e-01, -9.7822e-02,\n",
      "        -1.4096e-01,  7.1121e-01,  6.1933e-01, -2.5014e-01,  4.2250e-01,\n",
      "         4.8458e-01, -5.1915e-01,  7.7125e-01,  3.6685e-01,  4.9652e-01,\n",
      "        -4.1298e-02, -1.4683e+00,  2.0038e-01,  1.8591e-01,  4.9860e-02,\n",
      "        -1.7523e-01, -3.5528e-01,  9.4153e-01, -1.1898e-01, -5.1903e-01,\n",
      "        -1.1887e-02, -3.9186e-01, -1.7479e-01,  9.3451e-01, -5.8931e-01,\n",
      "        -2.7701e+00,  3.4522e-01,  8.6533e-01,  1.0808e+00, -1.0291e-01,\n",
      "        -9.1220e-02,  5.5092e-01, -3.9473e-01,  5.3676e-01,  1.0383e+00,\n",
      "        -4.0658e-01,  2.4590e-01, -2.6797e-01, -2.6036e-01, -1.4151e-01,\n",
      "        -1.2022e-01,  1.6234e-01, -7.4320e-01, -6.4728e-01,  4.7133e-02,\n",
      "         5.1642e-01,  1.9898e-01,  2.3919e-01,  1.2550e-01,  2.2471e-01,\n",
      "         8.2613e-01,  7.8328e-02, -5.7020e-01,  2.3934e-02, -1.5410e-01,\n",
      "        -2.5739e-01,  4.1262e-01, -4.6967e-01,  8.7914e-01,  7.2629e-01,\n",
      "         5.3862e-02, -1.1575e+00, -4.7835e-01,  2.0139e-01, -1.0051e+00,\n",
      "         1.1515e-01, -9.6609e-01,  1.2960e-01,  1.8388e-01, -3.0383e-02])\n",
      "Token[4]: \".\"\n",
      "tensor([-0.3398,  0.2094,  0.4635, -0.6479, -0.3838,  0.0380,  0.1713,  0.1598,\n",
      "         0.4662, -0.0192,  0.4148, -0.3435,  0.2687,  0.0446,  0.4213, -0.4103,\n",
      "         0.1546,  0.0222, -0.6465,  0.2526,  0.0431, -0.1945,  0.4652,  0.4565,\n",
      "         0.6859,  0.0913,  0.2188, -0.7035,  0.1679, -0.3508, -0.1263,  0.6638,\n",
      "        -0.2582,  0.0365, -0.1361,  0.4025,  0.1429,  0.3813, -0.1228, -0.4589,\n",
      "        -0.2528, -0.3043, -0.1121, -0.2618, -0.2248, -0.4455,  0.2991, -0.8561,\n",
      "        -0.1450, -0.4909,  0.0083, -0.1749,  0.2752,  1.4401, -0.2124, -2.8435,\n",
      "        -0.2796, -0.4572,  1.6386,  0.7881, -0.5526,  0.6500,  0.0864,  0.3901,\n",
      "         1.0632, -0.3538,  0.4833,  0.3460,  0.8417,  0.0987, -0.2421, -0.2705,\n",
      "         0.0453, -0.4015,  0.1139,  0.0062,  0.0367,  0.0185, -1.0213, -0.2081,\n",
      "         0.6407, -0.0688, -0.5864,  0.3348, -1.1432, -0.1148, -0.2509, -0.4591,\n",
      "        -0.0968, -0.1795, -0.0634, -0.6741, -0.0689,  0.5360, -0.8777,  0.3180,\n",
      "        -0.3924, -0.2339,  0.4730, -0.0288])\n"
     ]
    }
   ],
   "source": [
    "# create sentence.\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed a sentence using glove.\n",
    "glove_embedding.embed(sentence)\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[Sentence: \"The grass is green .\"]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import FlairEmbeddings\n",
    "\n",
    "# init embedding\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "flair_embedding_forward.embed(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-31 20:50:33,785 https://nlp.informatik.hu-berlin.de/resources/models/tars-base/tars-base-v8.pt not found in cache, downloading to /var/folders/qw/p9g8lbb956g4ztks742q3tf40000gn/T/tmptysocyme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438064585/438064585 [01:17<00:00, 5621453.49B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-31 20:51:51,918 copying /var/folders/qw/p9g8lbb956g4ztks742q3tf40000gn/T/tmptysocyme to cache at /Users/zad/.flair/models/tars-base-v8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-31 20:51:52,726 removing temp file /var/folders/qw/p9g8lbb956g4ztks742q3tf40000gn/T/tmptysocyme\n",
      "2022-05-31 20:51:52,885 loading file /Users/zad/.flair/models/tars-base-v8.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=28.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd4147b0c5b4465eb512bb6defdf87dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=570.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a40c875456748c590bde6074438d361"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aacd43265c26482b9d1bc604015d0991"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=466062.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8768c7011fc84e1ebd0e070963f3ee24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: \"I am so glad you liked it !\" → happy (0.8667)\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TARSClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# 1. Load our pre-trained TARS model for English\n",
    "tars = TARSClassifier.load('tars-base')\n",
    "\n",
    "# 2. Prepare a test sentence\n",
    "sentence = Sentence(\"I am so glad you liked it!\")\n",
    "\n",
    "# 3. Define some classes that you want to predict using descriptive names\n",
    "classes = [\"happy\", \"sad\"]\n",
    "#4. Predict for these classes\n",
    "tars.predict_zero_shot(sentence, classes)\n",
    "\n",
    "# Print sentence with predicted labels\n",
    "print(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-31 20:54:28,371 loading file /Users/zad/.flair/models/tars-base-v8.pt\n",
      "Sentence: \"I am so glad you liked it !\"\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TARSClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# 1. Load our pre-trained TARS model for English\n",
    "tars = TARSClassifier.load('tars-base')\n",
    "\n",
    "# 2. Prepare a test sentence\n",
    "sentence = Sentence(\"I am so glad you liked it!\")\n",
    "\n",
    "# 3. Define some classes that you want to predict using descriptive names\n",
    "# classes = [\"happy\", \"sad\"]\n",
    "classes = ['assertive', \"hesitant\"]\n",
    "#4. Predict for these classes\n",
    "tars.predict_zero_shot(sentence, classes)\n",
    "\n",
    "# Print sentence with predicted labels\n",
    "print(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-31 21:10:04,545 loading file /Users/zad/.flair/models/tars-ner.pt\n",
      "2022-05-31 21:10:26,410 SequenceTagger predicts: Dictionary with 5 tags: O, S-entity, B-entity, E-entity, I-entity\n",
      "Sentence: \"We outperformed the S & P 's 500 \")\" → [\"S & P\"/Company, \"500\"/Benchmark]\n",
      "Sentence: \"Our benchmark is the LIBOR\" → [\"LIBOR\"/Benchmark]\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TARSTagger\n",
    "from flair.data import Sentence\n",
    "\n",
    "# 1. Load zero-shot NER tagger\n",
    "tars = TARSTagger.load('tars-ner')\n",
    "\n",
    "# 2. Prepare some test sentences\n",
    "sentences = [\n",
    "    Sentence('We outperformed the S&P\\'s 500\")'),\n",
    "    Sentence('Our benchmark is the LIBOR')\n",
    "\n",
    "    # Sentence(\"The Humboldt University of Berlin is situated near the Spree in Berlin, Germany\"),\n",
    "    # Sentence(\"Bayern Munich played against Real Madrid\"),\n",
    "    # Sentence(\"I flew with an Airbus A380 to Peru to pick up my Porsche Cayenne\"),\n",
    "    # Sentence(\"Game of Thrones is my favorite series\"),\n",
    "]\n",
    "\n",
    "# 3. Define some classes of named entities such as \"soccer teams\", \"TV shows\" and \"rivers\"\n",
    "labels = [\"Company\", \"Fund\", \"Mutual Fund\", \"Finance Instituion\" , 'Index', 'Index Fund', 'Benchmark']\n",
    "tars.add_and_switch_to_new_task('task 1', labels, label_type='ner')\n",
    "\n",
    "# 4. Predict for these classes and print results\n",
    "for sentence in sentences:\n",
    "    tars.predict(sentence)\n",
    "    print(sentence.to_tagged_string(\"ner\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import TREC_6\n",
    "from flair.models import TARSClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "# 1. define label names in natural language since some datasets come with cryptic set of labels\n",
    "label_name_map = {'ENTY': 'question about entity',\n",
    "                  'DESC': 'question about description',\n",
    "                  'ABBR': 'question about abbreviation',\n",
    "                  'HUM': 'question about person',\n",
    "                  'NUM': 'question about number',\n",
    "                  'LOC': 'question about location'\n",
    "                  }\n",
    "\n",
    "# 2. get the corpus\n",
    "corpus: Corpus = TREC_6(label_name_map=label_name_map)\n",
    "\n",
    "# 3. what label do you want to predict?\n",
    "label_type = 'question_class'\n",
    "\n",
    "# 4. make a label dictionary\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
    "\n",
    "# 5. start from our existing TARS base model for English\n",
    "tars = TARSClassifier.load(\"tars-base\")\n",
    "\n",
    "# 5a: alternatively, comment out previous line and comment in next line to train a new TARS model from scratch instead\n",
    "# tars = TARSClassifier(embeddings=\"bert-base-uncased\")\n",
    "\n",
    "# 6. switch to a new task (TARS can do multiple tasks so you must define one)\n",
    "tars.add_and_switch_to_new_task(task_name=\"question classification\",\n",
    "                                label_dictionary=label_dict,\n",
    "                                label_type=label_type,\n",
    "                                )\n",
    "\n",
    "# 7. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(tars, corpus)\n",
    "\n",
    "# 8. start the training\n",
    "trainer.train(base_path='resources/taggers/trec',  # path to store the model artifacts\n",
    "              learning_rate=0.02,  # use very small learning rate\n",
    "              mini_batch_size=16,\n",
    "              mini_batch_chunk_size=4,  # optionally set this if transformer is too much for your machine\n",
    "              max_epochs=1,  # terminate after 10 epochs\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
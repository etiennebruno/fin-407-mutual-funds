{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')\n",
    "s = flair.data.Sentence(txt)\n",
    "flair_sentiment.predict(s)\n",
    "total_sentiment = s.labels\n",
    "total_sentiment\n",
    "s.tag, s.score\n",
    "flair_sentiment.predict(s);\n",
    "s.labels\n",
    "# from flair.data_fetcher import NLPTask\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "sec_corpus = flair.datasets.NER_ENGLISH_SEC_FILLINGS()\n",
    "print(sec_corpus.obtain_statistics())\n",
    "word_embeddings = [WordEmbeddings('glove'),\n",
    "                   FlairEmbeddings('news-forward'),\n",
    "                   FlairEmbeddings('news-backward'),\n",
    "                   ]\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings  #, Sentence\n",
    "\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "flair_embedding_backward = FlairEmbeddings('news-backward')\n",
    "\n",
    "document_embeddings = DocumentPoolEmbeddings([glove_embedding,\n",
    "                                              flair_embedding_backward,\n",
    "                                              flair_embedding_backward],\n",
    "                                             mode='min')\n",
    "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                                   hidden_size=512,\n",
    "                                                                   reproject_words=True,\n",
    "                                                                   reproject_words_dimension=256,\n",
    "                                                                   )\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_type=, multi_label=False)\n",
    "\n",
    "from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n",
    "\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings([glove_embedding])\n",
    "sentence = Sentence('The grass is green . And the sky is blue .')\n",
    "\n",
    "document_embeddings.embed(sentence)\n",
    "\n",
    "print(sentence.get_embedding())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import flair\n",
    "from flair.datasets import UD_ENGLISH\n",
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:23:39,192 https://raw.githubusercontent.com/juand-r/entity-recognition-datasets/master/data/SEC-filings/CONLL-format/data/test/FIN3.txt not found in cache, downloading to /var/folders/kw/xkx354ds5q76y81wmz9s5w980000gn/T/tmprlbxgihj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167860B [00:00, 26733591.64B/s]                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:23:39,316 copying /var/folders/kw/xkx354ds5q76y81wmz9s5w980000gn/T/tmprlbxgihj to cache at /Users/etiennebruno/.flair/datasets/ner_english_sec_fillings/FIN3.txt\n",
      "2022-05-30 20:23:39,317 removing temp file /var/folders/kw/xkx354ds5q76y81wmz9s5w980000gn/T/tmprlbxgihj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:23:39,584 https://raw.githubusercontent.com/juand-r/entity-recognition-datasets/master/data/SEC-filings/CONLL-format/data/train/FIN5.txt not found in cache, downloading to /var/folders/kw/xkx354ds5q76y81wmz9s5w980000gn/T/tmpu1nhhhyo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "523060B [00:00, 24424669.35B/s]                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:23:39,773 copying /var/folders/kw/xkx354ds5q76y81wmz9s5w980000gn/T/tmpu1nhhhyo to cache at /Users/etiennebruno/.flair/datasets/ner_english_sec_fillings/FIN5.txt\n",
      "2022-05-30 20:23:39,776 removing temp file /var/folders/kw/xkx354ds5q76y81wmz9s5w980000gn/T/tmpu1nhhhyo\n",
      "2022-05-30 20:23:39,779 Reading data from /Users/etiennebruno/.flair/datasets/ner_english_sec_fillings\n",
      "2022-05-30 20:23:39,784 Train: /Users/etiennebruno/.flair/datasets/ner_english_sec_fillings/FIN5.txt\n",
      "2022-05-30 20:23:39,786 Dev: None\n",
      "2022-05-30 20:23:39,786 Test: /Users/etiennebruno/.flair/datasets/ner_english_sec_fillings/FIN3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = flair.datasets.NER_ENGLISH_SEC_FILLINGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label_type = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:23:42,215 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1051it [00:00, 20261.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:23:42,282 Dictionary created for label 'pos' with 42 values: NNP (seen 5586 times), NN (seen 5105 times), IN (seen 4365 times), DT (seen 3811 times), NNS (seen 2114 times), CC (seen 2096 times), , (seen 1883 times), JJ (seen 1732 times), CD (seen 1366 times), : (seen 1318 times), . (seen 1232 times), VBN (seen 947 times), VB (seen 934 times), TO (seen 896 times), VBZ (seen 680 times), RB (seen 629 times), MD (seen 439 times), VBG (seen 430 times), VBD (seen 330 times), VBP (seen 312 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_dict = corpus.make_label_dictionary(label_type=label_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CharacterEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 4. initialize embeddings\u001b[39;00m\n\u001b[1;32m      2\u001b[0m embedding_types \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m     WordEmbeddings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglove\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# comment in this line to use character embeddings\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m      \u001b[43mCharacterEmbeddings\u001b[49m(),\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# comment in these lines to use flair embeddings\u001b[39;00m\n\u001b[1;32m     10\u001b[0m      FlairEmbeddings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews-forward\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     11\u001b[0m      FlairEmbeddings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews-backward\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     12\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CharacterEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "     CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "     FlairEmbeddings('news-forward'),\n",
    "     FlairEmbeddings('news-backward'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 5. initialize sequence tagger\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type=label_type,\n",
    "                        use_crf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 6. initialize trainer\n",
    "trainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:42:57,202 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:42:57,203 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=44, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-05-30 20:42:57,203 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:42:57,204 Corpus: \"Corpus: 1051 train + 117 dev + 305 test sentences\"\n",
      "2022-05-30 20:42:57,204 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:42:57,205 Parameters:\n",
      "2022-05-30 20:42:57,205  - learning_rate: \"0.100000\"\n",
      "2022-05-30 20:42:57,206  - mini_batch_size: \"32\"\n",
      "2022-05-30 20:42:57,206  - patience: \"3\"\n",
      "2022-05-30 20:42:57,207  - anneal_factor: \"0.5\"\n",
      "2022-05-30 20:42:57,207  - max_epochs: \"10\"\n",
      "2022-05-30 20:42:57,208  - shuffle: \"True\"\n",
      "2022-05-30 20:42:57,208  - train_with_dev: \"False\"\n",
      "2022-05-30 20:42:57,209  - batch_growth_annealing: \"False\"\n",
      "2022-05-30 20:42:57,209 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:42:57,210 Model training base path: \"resources/taggers/example-upos\"\n",
      "2022-05-30 20:42:57,210 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:42:57,211 Device: cpu\n",
      "2022-05-30 20:42:57,212 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:42:57,212 Embeddings storage mode: cpu\n",
      "2022-05-30 20:42:57,213 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/flair/trainers/trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:42:58,953 epoch 1 - iter 3/33 - loss 1.01682098 - samples/sec: 55.20 - lr: 0.100000\n",
      "2022-05-30 20:43:01,894 epoch 1 - iter 6/33 - loss 1.04294419 - samples/sec: 32.66 - lr: 0.100000\n",
      "2022-05-30 20:43:04,458 epoch 1 - iter 9/33 - loss 1.07340072 - samples/sec: 37.46 - lr: 0.100000\n",
      "2022-05-30 20:43:07,035 epoch 1 - iter 12/33 - loss 1.04021959 - samples/sec: 37.25 - lr: 0.100000\n",
      "2022-05-30 20:43:09,553 epoch 1 - iter 15/33 - loss 0.99827320 - samples/sec: 38.15 - lr: 0.100000\n",
      "2022-05-30 20:43:10,845 epoch 1 - iter 18/33 - loss 1.02313148 - samples/sec: 74.31 - lr: 0.100000\n",
      "2022-05-30 20:43:17,153 epoch 1 - iter 21/33 - loss 1.03123524 - samples/sec: 15.22 - lr: 0.100000\n",
      "2022-05-30 20:43:24,792 epoch 1 - iter 24/33 - loss 1.03370120 - samples/sec: 12.57 - lr: 0.100000\n",
      "2022-05-30 20:43:29,303 epoch 1 - iter 27/33 - loss 1.04273997 - samples/sec: 21.28 - lr: 0.100000\n",
      "2022-05-30 20:43:37,094 epoch 1 - iter 30/33 - loss 1.04857766 - samples/sec: 12.32 - lr: 0.100000\n",
      "2022-05-30 20:43:39,551 epoch 1 - iter 33/33 - loss 1.03252957 - samples/sec: 39.09 - lr: 0.100000\n",
      "2022-05-30 20:43:39,551 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:43:39,552 EPOCH 1 done: loss 1.0325 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:43:40,371 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:43:40,458 DEV : loss 0.7023018598556519 - f1-score (micro avg)  0.7716\n",
      "2022-05-30 20:43:40,464 BAD EPOCHS (no improvement): 0\n",
      "2022-05-30 20:43:40,465 saving best model\n",
      "2022-05-30 20:43:40,817 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:43:43,688 epoch 2 - iter 3/33 - loss 1.03609126 - samples/sec: 33.47 - lr: 0.100000\n",
      "2022-05-30 20:43:49,083 epoch 2 - iter 6/33 - loss 1.01897401 - samples/sec: 17.80 - lr: 0.100000\n",
      "2022-05-30 20:43:53,989 epoch 2 - iter 9/33 - loss 0.99378321 - samples/sec: 19.57 - lr: 0.100000\n",
      "2022-05-30 20:44:00,040 epoch 2 - iter 12/33 - loss 1.01432561 - samples/sec: 15.87 - lr: 0.100000\n",
      "2022-05-30 20:44:06,930 epoch 2 - iter 15/33 - loss 1.00892106 - samples/sec: 13.94 - lr: 0.100000\n",
      "2022-05-30 20:44:10,376 epoch 2 - iter 18/33 - loss 1.01045039 - samples/sec: 27.86 - lr: 0.100000\n",
      "2022-05-30 20:44:13,398 epoch 2 - iter 21/33 - loss 1.00651289 - samples/sec: 31.78 - lr: 0.100000\n",
      "2022-05-30 20:44:16,883 epoch 2 - iter 24/33 - loss 0.99908178 - samples/sec: 27.55 - lr: 0.100000\n",
      "2022-05-30 20:44:22,727 epoch 2 - iter 27/33 - loss 1.00016480 - samples/sec: 16.43 - lr: 0.100000\n",
      "2022-05-30 20:44:26,491 epoch 2 - iter 30/33 - loss 0.99593775 - samples/sec: 25.51 - lr: 0.100000\n",
      "2022-05-30 20:44:28,915 epoch 2 - iter 33/33 - loss 0.98880962 - samples/sec: 39.61 - lr: 0.100000\n",
      "2022-05-30 20:44:28,916 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:44:28,917 EPOCH 2 done: loss 0.9888 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:29,722 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:44:29,741 DEV : loss 0.6789711117744446 - f1-score (micro avg)  0.7774\n",
      "2022-05-30 20:44:29,747 BAD EPOCHS (no improvement): 0\n",
      "2022-05-30 20:44:29,748 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:44:30,146 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:44:37,177 epoch 3 - iter 3/33 - loss 1.03597281 - samples/sec: 13.66 - lr: 0.100000\n",
      "2022-05-30 20:44:38,422 epoch 3 - iter 6/33 - loss 1.00972544 - samples/sec: 77.15 - lr: 0.100000\n",
      "2022-05-30 20:44:42,718 epoch 3 - iter 9/33 - loss 0.98691081 - samples/sec: 22.35 - lr: 0.100000\n",
      "2022-05-30 20:44:48,440 epoch 3 - iter 12/33 - loss 0.97068105 - samples/sec: 16.78 - lr: 0.100000\n",
      "2022-05-30 20:44:54,890 epoch 3 - iter 15/33 - loss 0.96851327 - samples/sec: 14.89 - lr: 0.100000\n",
      "2022-05-30 20:44:58,871 epoch 3 - iter 18/33 - loss 0.96309837 - samples/sec: 24.12 - lr: 0.100000\n",
      "2022-05-30 20:45:03,355 epoch 3 - iter 21/33 - loss 0.96695845 - samples/sec: 21.41 - lr: 0.100000\n",
      "2022-05-30 20:45:08,960 epoch 3 - iter 24/33 - loss 0.95766887 - samples/sec: 17.13 - lr: 0.100000\n",
      "2022-05-30 20:45:15,940 epoch 3 - iter 27/33 - loss 0.95765601 - samples/sec: 13.76 - lr: 0.100000\n",
      "2022-05-30 20:45:20,734 epoch 3 - iter 30/33 - loss 0.96091346 - samples/sec: 20.03 - lr: 0.100000\n",
      "2022-05-30 20:45:23,985 epoch 3 - iter 33/33 - loss 0.96318766 - samples/sec: 29.54 - lr: 0.100000\n",
      "2022-05-30 20:45:23,985 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:45:23,986 EPOCH 3 done: loss 0.9632 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:45:25,045 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:45:25,063 DEV : loss 0.6370547413825989 - f1-score (micro avg)  0.7783\n",
      "2022-05-30 20:45:25,069 BAD EPOCHS (no improvement): 0\n",
      "2022-05-30 20:45:25,070 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:45:25,419 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:45:31,999 epoch 4 - iter 3/33 - loss 1.02206256 - samples/sec: 14.59 - lr: 0.100000\n",
      "2022-05-30 20:45:35,955 epoch 4 - iter 6/33 - loss 0.97533656 - samples/sec: 24.28 - lr: 0.100000\n",
      "2022-05-30 20:45:39,968 epoch 4 - iter 9/33 - loss 0.95695531 - samples/sec: 23.92 - lr: 0.100000\n",
      "2022-05-30 20:45:43,040 epoch 4 - iter 12/33 - loss 0.93815605 - samples/sec: 31.27 - lr: 0.100000\n",
      "2022-05-30 20:45:47,448 epoch 4 - iter 15/33 - loss 0.93158126 - samples/sec: 21.78 - lr: 0.100000\n",
      "2022-05-30 20:45:51,852 epoch 4 - iter 18/33 - loss 0.92457723 - samples/sec: 21.81 - lr: 0.100000\n",
      "2022-05-30 20:45:58,341 epoch 4 - iter 21/33 - loss 0.92741538 - samples/sec: 14.80 - lr: 0.100000\n",
      "2022-05-30 20:46:02,721 epoch 4 - iter 24/33 - loss 0.92578947 - samples/sec: 21.92 - lr: 0.100000\n",
      "2022-05-30 20:46:09,624 epoch 4 - iter 27/33 - loss 0.92839778 - samples/sec: 13.91 - lr: 0.100000\n",
      "2022-05-30 20:46:15,570 epoch 4 - iter 30/33 - loss 0.93985276 - samples/sec: 16.15 - lr: 0.100000\n",
      "2022-05-30 20:46:18,507 epoch 4 - iter 33/33 - loss 0.94179885 - samples/sec: 32.70 - lr: 0.100000\n",
      "2022-05-30 20:46:18,508 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:46:18,509 EPOCH 4 done: loss 0.9418 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:46:19,307 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:46:19,326 DEV : loss 0.6128749251365662 - f1-score (micro avg)  0.7934\n",
      "2022-05-30 20:46:19,331 BAD EPOCHS (no improvement): 0\n",
      "2022-05-30 20:46:19,332 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:46:19,683 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:46:21,846 epoch 5 - iter 3/33 - loss 0.97488842 - samples/sec: 44.39 - lr: 0.100000\n",
      "2022-05-30 20:46:25,567 epoch 5 - iter 6/33 - loss 0.96162897 - samples/sec: 25.81 - lr: 0.100000\n",
      "2022-05-30 20:46:30,714 epoch 5 - iter 9/33 - loss 0.93985456 - samples/sec: 18.66 - lr: 0.100000\n",
      "2022-05-30 20:46:38,211 epoch 5 - iter 12/33 - loss 0.95330191 - samples/sec: 12.81 - lr: 0.100000\n",
      "2022-05-30 20:46:40,414 epoch 5 - iter 15/33 - loss 0.94814286 - samples/sec: 43.59 - lr: 0.100000\n",
      "2022-05-30 20:46:44,856 epoch 5 - iter 18/33 - loss 0.94755922 - samples/sec: 21.62 - lr: 0.100000\n",
      "2022-05-30 20:46:50,593 epoch 5 - iter 21/33 - loss 0.94509592 - samples/sec: 16.74 - lr: 0.100000\n",
      "2022-05-30 20:46:55,445 epoch 5 - iter 24/33 - loss 0.93211287 - samples/sec: 19.79 - lr: 0.100000\n",
      "2022-05-30 20:46:58,164 epoch 5 - iter 27/33 - loss 0.93407956 - samples/sec: 35.32 - lr: 0.100000\n",
      "2022-05-30 20:47:03,467 epoch 5 - iter 30/33 - loss 0.92662252 - samples/sec: 18.10 - lr: 0.100000\n",
      "2022-05-30 20:47:07,393 epoch 5 - iter 33/33 - loss 0.92350258 - samples/sec: 24.46 - lr: 0.100000\n",
      "2022-05-30 20:47:07,394 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:47:07,394 EPOCH 5 done: loss 0.9235 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:47:08,210 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:47:08,228 DEV : loss 0.606508731842041 - f1-score (micro avg)  0.8006\n",
      "2022-05-30 20:47:08,234 BAD EPOCHS (no improvement): 0\n",
      "2022-05-30 20:47:08,234 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:47:08,582 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:47:12,612 epoch 6 - iter 3/33 - loss 0.85234553 - samples/sec: 23.83 - lr: 0.100000\n",
      "2022-05-30 20:47:22,497 epoch 6 - iter 6/33 - loss 0.88570344 - samples/sec: 9.71 - lr: 0.100000\n",
      "2022-05-30 20:47:25,978 epoch 6 - iter 9/33 - loss 0.92249845 - samples/sec: 27.59 - lr: 0.100000\n",
      "2022-05-30 20:47:31,241 epoch 6 - iter 12/33 - loss 0.91170606 - samples/sec: 18.24 - lr: 0.100000\n",
      "2022-05-30 20:47:34,857 epoch 6 - iter 15/33 - loss 0.91399605 - samples/sec: 26.55 - lr: 0.100000\n",
      "2022-05-30 20:47:37,143 epoch 6 - iter 18/33 - loss 0.90950970 - samples/sec: 42.02 - lr: 0.100000\n",
      "2022-05-30 20:47:40,132 epoch 6 - iter 21/33 - loss 0.90627364 - samples/sec: 32.12 - lr: 0.100000\n",
      "2022-05-30 20:47:44,724 epoch 6 - iter 24/33 - loss 0.90292996 - samples/sec: 20.91 - lr: 0.100000\n",
      "2022-05-30 20:47:48,051 epoch 6 - iter 27/33 - loss 0.89675237 - samples/sec: 28.86 - lr: 0.100000\n",
      "2022-05-30 20:47:53,594 epoch 6 - iter 30/33 - loss 0.89734416 - samples/sec: 17.32 - lr: 0.100000\n",
      "2022-05-30 20:47:56,841 epoch 6 - iter 33/33 - loss 0.88833407 - samples/sec: 29.57 - lr: 0.100000\n",
      "2022-05-30 20:47:56,842 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:47:56,842 EPOCH 6 done: loss 0.8883 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:47:57,644 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:47:57,663 DEV : loss 0.5761227607727051 - f1-score (micro avg)  0.816\n",
      "2022-05-30 20:47:57,669 BAD EPOCHS (no improvement): 0\n",
      "2022-05-30 20:47:57,670 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:47:58,013 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:48:03,977 epoch 7 - iter 3/33 - loss 0.89688200 - samples/sec: 16.10 - lr: 0.100000\n",
      "2022-05-30 20:48:07,580 epoch 7 - iter 6/33 - loss 0.89784507 - samples/sec: 26.65 - lr: 0.100000\n",
      "2022-05-30 20:48:10,521 epoch 7 - iter 9/33 - loss 0.87646999 - samples/sec: 32.65 - lr: 0.100000\n",
      "2022-05-30 20:48:14,266 epoch 7 - iter 12/33 - loss 0.88388458 - samples/sec: 25.65 - lr: 0.100000\n",
      "2022-05-30 20:48:20,540 epoch 7 - iter 15/33 - loss 0.88271943 - samples/sec: 15.30 - lr: 0.100000\n",
      "2022-05-30 20:48:22,420 epoch 7 - iter 18/33 - loss 0.87881911 - samples/sec: 51.11 - lr: 0.100000\n",
      "2022-05-30 20:48:25,407 epoch 7 - iter 21/33 - loss 0.87744155 - samples/sec: 32.14 - lr: 0.100000\n",
      "2022-05-30 20:48:34,763 epoch 7 - iter 24/33 - loss 0.87894649 - samples/sec: 10.26 - lr: 0.100000\n",
      "2022-05-30 20:48:37,975 epoch 7 - iter 27/33 - loss 0.88081229 - samples/sec: 29.89 - lr: 0.100000\n",
      "2022-05-30 20:48:42,952 epoch 7 - iter 30/33 - loss 0.87480439 - samples/sec: 19.29 - lr: 0.100000\n",
      "2022-05-30 20:48:47,353 epoch 7 - iter 33/33 - loss 0.87441270 - samples/sec: 21.82 - lr: 0.100000\n",
      "2022-05-30 20:48:47,354 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:48:47,355 EPOCH 7 done: loss 0.8744 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:48:48,167 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:48:48,186 DEV : loss 0.5578662753105164 - f1-score (micro avg)  0.8199\n",
      "2022-05-30 20:48:48,192 BAD EPOCHS (no improvement): 0\n",
      "2022-05-30 20:48:48,193 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:48:48,537 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:48:51,877 epoch 8 - iter 3/33 - loss 0.88031197 - samples/sec: 28.75 - lr: 0.100000\n",
      "2022-05-30 20:48:57,963 epoch 8 - iter 6/33 - loss 0.87312226 - samples/sec: 15.78 - lr: 0.100000\n",
      "2022-05-30 20:49:01,832 epoch 8 - iter 9/33 - loss 0.85971893 - samples/sec: 24.82 - lr: 0.100000\n",
      "2022-05-30 20:49:07,990 epoch 8 - iter 12/33 - loss 0.85753425 - samples/sec: 15.59 - lr: 0.100000\n",
      "2022-05-30 20:49:14,410 epoch 8 - iter 15/33 - loss 0.86989017 - samples/sec: 14.96 - lr: 0.100000\n",
      "2022-05-30 20:49:18,011 epoch 8 - iter 18/33 - loss 0.87178633 - samples/sec: 26.66 - lr: 0.100000\n",
      "2022-05-30 20:49:20,678 epoch 8 - iter 21/33 - loss 0.86250308 - samples/sec: 36.02 - lr: 0.100000\n",
      "2022-05-30 20:49:24,880 epoch 8 - iter 24/33 - loss 0.85446418 - samples/sec: 22.85 - lr: 0.100000\n",
      "2022-05-30 20:49:27,991 epoch 8 - iter 27/33 - loss 0.85215565 - samples/sec: 30.86 - lr: 0.100000\n",
      "2022-05-30 20:49:31,563 epoch 8 - iter 30/33 - loss 0.85167220 - samples/sec: 26.88 - lr: 0.100000\n",
      "2022-05-30 20:49:37,116 epoch 8 - iter 33/33 - loss 0.85715593 - samples/sec: 17.29 - lr: 0.100000\n",
      "2022-05-30 20:49:37,117 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:49:37,117 EPOCH 8 done: loss 0.8572 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:49:37,958 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:49:37,981 DEV : loss 0.5433512330055237 - f1-score (micro avg)  0.8232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:49:37,987 BAD EPOCHS (no improvement): 0\n",
      "2022-05-30 20:49:37,989 saving best model\n",
      "2022-05-30 20:49:38,352 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:49:44,835 epoch 9 - iter 3/33 - loss 0.88483628 - samples/sec: 14.81 - lr: 0.100000\n",
      "2022-05-30 20:49:50,842 epoch 9 - iter 6/33 - loss 0.85428550 - samples/sec: 15.98 - lr: 0.100000\n",
      "2022-05-30 20:49:54,350 epoch 9 - iter 9/33 - loss 0.86631484 - samples/sec: 27.37 - lr: 0.100000\n",
      "2022-05-30 20:49:59,193 epoch 9 - iter 12/33 - loss 0.87708737 - samples/sec: 19.83 - lr: 0.100000\n",
      "2022-05-30 20:50:02,365 epoch 9 - iter 15/33 - loss 0.85639022 - samples/sec: 30.27 - lr: 0.100000\n",
      "2022-05-30 20:50:11,860 epoch 9 - iter 18/33 - loss 0.85913506 - samples/sec: 10.11 - lr: 0.100000\n",
      "2022-05-30 20:50:15,368 epoch 9 - iter 21/33 - loss 0.84791279 - samples/sec: 27.37 - lr: 0.100000\n",
      "2022-05-30 20:50:18,926 epoch 9 - iter 24/33 - loss 0.85078300 - samples/sec: 26.99 - lr: 0.100000\n",
      "2022-05-30 20:50:23,153 epoch 9 - iter 27/33 - loss 0.85118596 - samples/sec: 22.72 - lr: 0.100000\n",
      "2022-05-30 20:50:25,933 epoch 9 - iter 30/33 - loss 0.84346883 - samples/sec: 34.55 - lr: 0.100000\n",
      "2022-05-30 20:50:29,164 epoch 9 - iter 33/33 - loss 0.84172001 - samples/sec: 29.72 - lr: 0.100000\n",
      "2022-05-30 20:50:29,165 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:50:29,165 EPOCH 9 done: loss 0.8417 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:50:29,969 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:50:29,988 DEV : loss 0.5508217215538025 - f1-score (micro avg)  0.8151\n",
      "2022-05-30 20:50:29,994 BAD EPOCHS (no improvement): 1\n",
      "2022-05-30 20:50:29,995 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:50:34,325 epoch 10 - iter 3/33 - loss 0.85683147 - samples/sec: 22.18 - lr: 0.100000\n",
      "2022-05-30 20:50:41,849 epoch 10 - iter 6/33 - loss 0.86890986 - samples/sec: 12.76 - lr: 0.100000\n",
      "2022-05-30 20:50:45,130 epoch 10 - iter 9/33 - loss 0.84860668 - samples/sec: 29.26 - lr: 0.100000\n",
      "2022-05-30 20:50:49,764 epoch 10 - iter 12/33 - loss 0.84291686 - samples/sec: 20.72 - lr: 0.100000\n",
      "2022-05-30 20:50:56,334 epoch 10 - iter 15/33 - loss 0.84146046 - samples/sec: 14.61 - lr: 0.100000\n",
      "2022-05-30 20:50:59,608 epoch 10 - iter 18/33 - loss 0.82934228 - samples/sec: 29.33 - lr: 0.100000\n",
      "2022-05-30 20:51:03,934 epoch 10 - iter 21/33 - loss 0.82462613 - samples/sec: 22.20 - lr: 0.100000\n",
      "2022-05-30 20:51:09,675 epoch 10 - iter 24/33 - loss 0.82077593 - samples/sec: 16.72 - lr: 0.100000\n",
      "2022-05-30 20:51:11,915 epoch 10 - iter 27/33 - loss 0.82821601 - samples/sec: 42.87 - lr: 0.100000\n",
      "2022-05-30 20:51:14,315 epoch 10 - iter 30/33 - loss 0.82132964 - samples/sec: 40.02 - lr: 0.100000\n",
      "2022-05-30 20:51:19,431 epoch 10 - iter 33/33 - loss 0.82464022 - samples/sec: 18.77 - lr: 0.100000\n",
      "2022-05-30 20:51:19,431 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:51:19,432 EPOCH 10 done: loss 0.8246 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:51:20,513 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:51:20,534 DEV : loss 0.5127765536308289 - f1-score (micro avg)  0.8324\n",
      "2022-05-30 20:51:20,540 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:51:20,542 saving best model\n",
      "2022-05-30 20:51:21,221 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-30 20:51:21,222 loading file resources/taggers/example-upos/best-model.pt\n",
      "2022-05-30 20:51:21,409 SequenceTagger predicts: Dictionary with 44 tags: <unk>, NNP, NN, IN, DT, NNS, CC, ,, JJ, CD, :, ., VBN, VB, TO, VBZ, RB, MD, VBG, VBD, VBP, PRP$, POS, WDT, LS, PRP, NNPS, '', JJR, WRB, JJS, $, ``, EX, -NONE-, RP, RBR, PDT, WP$, RBS, WP, -X-, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:51:24,750 Evaluating as a multi-label problem: False\n",
      "2022-05-30 20:51:24,817 0.8197\t0.8197\t0.8197\t0.8197\n",
      "2022-05-30 20:51:24,818 \n",
      "Results:\n",
      "- F-score (micro) 0.8197\n",
      "- F-score (macro) 0.4914\n",
      "- Accuracy 0.8197\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NN     0.6585    0.7569    0.7043      1806\n",
      "         NNP     0.7638    0.6201    0.6845      1961\n",
      "          IN     0.8894    0.9592    0.9230      1593\n",
      "          DT     0.9586    0.9885    0.9733      1570\n",
      "          CC     0.9750    0.9866    0.9808       673\n",
      "          JJ     0.6923    0.6934    0.6929       636\n",
      "           ,     0.9902    0.9728    0.9815       626\n",
      "          CD     0.8524    0.8569    0.8547       573\n",
      "         NNS     0.6805    0.6912    0.6858       570\n",
      "           :     0.7549    0.8770    0.8114       488\n",
      "           .     0.9786    0.9952    0.9868       413\n",
      "          VB     0.8144    0.8977    0.8540       391\n",
      "          TO     0.9784    1.0000    0.9891       363\n",
      "         VBN     0.7437    0.7923    0.7672       337\n",
      "          MD     0.8996    0.9956    0.9451       225\n",
      "          RB     0.6269    0.6020    0.6142       201\n",
      "         VBZ     0.8261    0.7755    0.8000       147\n",
      "         VBD     0.4270    0.3248    0.3689       117\n",
      "         VBG     0.6538    0.4215    0.5126       121\n",
      "         VBP     0.9412    0.4948    0.6486        97\n",
      "        PRP$     0.9841    0.9538    0.9688        65\n",
      "         WDT     0.9348    0.7818    0.8515        55\n",
      "         PRP     0.8605    0.7255    0.7872        51\n",
      "         POS     0.7619    1.0000    0.8649        32\n",
      "        NNPS     0.2500    0.0244    0.0444        41\n",
      "          LS     0.7000    0.2414    0.3590        29\n",
      "         JJR     0.0000    0.0000    0.0000        16\n",
      "          ''     0.0000    0.0000    0.0000        10\n",
      "          RP     0.0000    0.0000    0.0000         9\n",
      "         WRB     0.0000    0.0000    0.0000         6\n",
      "          ``     0.0000    0.0000    0.0000         6\n",
      "      -NONE-     0.0000    0.0000    0.0000         5\n",
      "         WP$     0.0000    0.0000    0.0000         3\n",
      "         JJS     0.0000    0.0000    0.0000         2\n",
      "          EX     0.0000    0.0000    0.0000         2\n",
      "         -X-     0.0000    0.0000    0.0000         2\n",
      "         RBR     0.0000    0.0000    0.0000         2\n",
      "           $     0.0000    0.0000    0.0000         2\n",
      "         PDT     0.0000    0.0000    0.0000         1\n",
      "          WP     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.8197     13248\n",
      "   macro avg     0.5149    0.4857    0.4914     13248\n",
      "weighted avg     0.8139    0.8197    0.8133     13248\n",
      "\n",
      "2022-05-30 20:51:24,818 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8197463768115942,\n",
       " 'dev_score_history': [0.7715721865400726,\n",
       "  0.777436470259704,\n",
       "  0.7782742250767942,\n",
       "  0.7933538117844178,\n",
       "  0.8006143535325329,\n",
       "  0.8159731918458532,\n",
       "  0.8198827143256073,\n",
       "  0.8232337335939681,\n",
       "  0.8151354370287629,\n",
       "  0.8324490365819603],\n",
       " 'train_loss_history': [1.0325295742378497,\n",
       "  0.9888096223147728,\n",
       "  0.9631876550413973,\n",
       "  0.9417988501992212,\n",
       "  0.92350258242295,\n",
       "  0.8883340689667553,\n",
       "  0.8744126978643426,\n",
       "  0.8571559276015643,\n",
       "  0.841720006612873,\n",
       "  0.8246402215061988],\n",
       " 'dev_loss_history': [0.7023018598556519,\n",
       "  0.6789711117744446,\n",
       "  0.6370547413825989,\n",
       "  0.6128749251365662,\n",
       "  0.606508731842041,\n",
       "  0.5761227607727051,\n",
       "  0.5578662753105164,\n",
       "  0.5433512330055237,\n",
       "  0.5508217215538025,\n",
       "  0.5127765536308289]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-upos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-30 21:13:52,066 loading file resources/taggers/example-upos/final-model.pt\n",
      "2022-05-30 21:13:52,263 SequenceTagger predicts: Dictionary with 44 tags: <unk>, NNP, NN, IN, DT, NNS, CC, ,, JJ, CD, :, ., VBN, VB, TO, VBZ, RB, MD, VBG, VBD, VBP, PRP$, POS, WDT, LS, PRP, NNPS, '', JJR, WRB, JJS, $, ``, EX, -NONE-, RP, RBR, PDT, WP$, RBS, WP, -X-, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# load the model you trained\n",
    "model = SequenceTagger.load('resources/taggers/example-upos/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/etiennebruno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from flair.data import Sentence\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNS 0.42820659279823303\n"
     ]
    }
   ],
   "source": [
    "df = df_from_filings()\n",
    "data = df.text[0]\n",
    "\n",
    "for sentence in TextBlob(df.text[0]).sentences[20:]: \n",
    "    s = Sentence(sentence)\n",
    "    model.predict(s)\n",
    "    \n",
    "    print(s.tag, s.score)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.06307071851174932, subjectivity=0.3252791047736546)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(df.text[0]).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0001553197, 0001553197, 0001553197, 0001553197, 0001553197, 0001553197, 0001553197, 0001553197, 0001553197, 0001553197'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(df.cik[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
